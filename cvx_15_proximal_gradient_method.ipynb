{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Decomposable functions"
      ],
      "metadata": {
        "id": "u6acydXJCNEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall the concept of `gradient descent` is to, at iteration $k$, minimize the quadratic approximation of $f$ at $x^k$\n",
        "\n",
        "$$x^{k+1}=\\arg \\min_xf(x^{k})+\\nabla f(x^{k})^T(x-x^{k})+\\frac{1}{2t^k}\\|x-x^{k}\\|_2^2$$\n",
        "\n",
        "We take derivative and set it to zero\n",
        "\n",
        "$$0+\\nabla f(x^{k})+\\frac{1}{t^k}(x-x^{k})=0$$\n",
        "\n",
        "and we get the gradient descent equation\n",
        "\n",
        "$$x^{k+1}=x^{k}-t^k \\nabla f(x^{k})$$"
      ],
      "metadata": {
        "id": "u4GjcTQXAz2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main motivation of proximal gradient method is that, when $f$ is not differentiable, rather than replacing the whole thing using subgradient, which we have seen is slow, we would like to keep some portion of this quadratic approximation\n",
        "\n",
        "In particular, we look at function\n",
        "\n",
        "$$f(x)=g(x)+h(x)$$\n",
        "\n",
        "where $g$ is differentiable while $h$ is not\n",
        "\n",
        "and we apply the quadratic approximation to $g$\n",
        "\n",
        "$$\\begin{align*}\n",
        "x^+ &  \\approx \\arg \\min_z g(x)+\\nabla g(x)^T(z-x)+\\frac{1}{2t}\\|z-x\\|_2^2+h(z)\\\\\n",
        "& g(x), \\nabla g(x) \\text{ as individual term has no effect on minimization over z}\\\\\n",
        " & = \\arg \\min_z \\frac{1}{2} t\\|\\nabla g(x)\\|_2^2+g(x)^T(z-x)+\\frac{1}{2t}\\|z-x\\|_2^2+h(z)\\\\\n",
        "&=\\arg\\min_z\\frac{1}{2t}\\|z-\\left(x-t\\nabla g(x)\\right)\\|_2^2+h(z)\n",
        "\\end{align*}$$\n",
        "\n",
        "Now we can see that we try to find a $z$ such that\n",
        "\n",
        "* we stay close to gradient update of $g$ by minimizing $\\|z-\\left(x-t\\nabla g(x)\\right)\\|_2^2$\n",
        "* we want to make $h$ small by minimizing $h(z)$"
      ],
      "metadata": {
        "id": "pwiTSDI4GFhl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wCZw3atoMDrj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}