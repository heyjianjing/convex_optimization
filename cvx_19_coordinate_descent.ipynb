{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Coordinate-wise optimality"
      ],
      "metadata": {
        "id": "D4P76UVhbYme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Differentiable function"
      ],
      "metadata": {
        "id": "kwzq5q0aCaOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a convex, differentiable $f$, if we are at a point $x$ such that $f(x)$ is minimized along each coordinate axis\n",
        "\n",
        "$$f(x+\\delta e_i)\\geq f(x)\\, \\forall \\delta , i$$\n",
        "\n",
        "then $x$ is the global minimizer\n",
        "\n",
        "This is because\n",
        "\n",
        "$$\\nabla f(x)=\\left(\\frac{\\partial f}{\\partial x_1}(x), \\cdots, \\frac{\\partial f}{\\partial x_n}(x)\\right)=0$$\n",
        "\n",
        "as each element in $\\nabla f(x)$ is minimized at $x$"
      ],
      "metadata": {
        "id": "mA_vt2GferWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Separable function"
      ],
      "metadata": {
        "id": "Z2Wo_7BRCckl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we consider the function\n",
        "\n",
        "$$f(x)=g(x)+\\sum_{i=1}^nh_i(x_i)$$\n",
        "\n",
        "where $g$ is convex and differentiable and each $h_i$ is only convex\n",
        "\n",
        "Since $x$ is such $f(x)$ is minimized along each coordinate axis, then for a point $y$, with subdifferential, we have\n",
        "\n",
        "$$\\begin{align*}\n",
        "0 &\\in \\nabla_i g(x)+\\partial h_i(x_i) \\\\\n",
        "&\\Longleftrightarrow -\\nabla_ig(x)\\in \\partial h_i(x_i)\\\\\n",
        "&\\Longleftrightarrow h_i(y_i)\\geq h_i(x_i)-\\nabla_ig(x)(y_i-x_i)\\\\\n",
        "&\\Longleftrightarrow \\nabla_ig(x)(y_i-x_i)+h_i(y_i)-h_i(x_i)\\geq 0\\\\\n",
        "\\end{align*}$$"
      ],
      "metadata": {
        "id": "SDELdv-J_Nth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we can write\n",
        "\n",
        "$$\\begin{align*}\n",
        "f(y)-f(x)&=g(y)-g(x)+\\sum_{i=1}^n \\left(h_i(y_i)-h_i(x_i)\\right) \\\\\n",
        "&\\geq \\nabla g(x)^T(y-x)+\\sum_{i=1}^n \\left(h_i(y_i)-h_i(x_i)\\right)\\\\\n",
        "&=\\sum_{i=1}^n \\left[\\nabla_ig(x)(y_i-x_i)+h_i(y_i)-h_i(x_i)\\right]\\\\\n",
        "&\\geq 0\n",
        "\\end{align*}$$\n",
        "\n",
        "Therefore, for separable $f$ here, if it is minimized along each coordinate axis, we also find the global optimizer"
      ],
      "metadata": {
        "id": "W1t4awK5A9MC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### General non-differentiable function"
      ],
      "metadata": {
        "id": "LoOsyjXhGRJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, the conclusion is NOT true if $f(x)$ is convex, but not differentiable in general"
      ],
      "metadata": {
        "id": "VnQYWJtWGEE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Coordinate descent"
      ],
      "metadata": {
        "id": "DZvxsrflHVXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For problem\n",
        "\n",
        "$$\\min_x f(x)$$\n",
        "\n",
        "where\n",
        "\n",
        "$$f(x)=g(x)+\\sum_{i=1}^nh_i(x_i)$$\n",
        "\n",
        "with $g$ is convex and differentiable and each $h_i$ is only convex\n",
        "\n",
        "and for some $x^0\\in \\mathbf{R}^n$, `coordinate descent` repeats\n",
        "\n",
        "$$x_i^{k+1}=\\arg\\min_{x_i}f\\left(x_1^{k+1}, \\cdots, x_{i-1}^{k+1}, x_i, x_{i+1}^k,\\cdots, x_n^k\\right)$$\n",
        "\n",
        "Here, we assume $x_1^{k+1}, \\cdots, x_{i-1}^{k+1}$ have been updated and their updated version is used\n",
        "\n",
        "Although in practice, the order of update does not really matter"
      ],
      "metadata": {
        "id": "cVwWsMcFHX-F"
      }
    }
  ]
}