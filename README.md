# Convex optimization

Main reference
* Lectures from Prof. Stephen Boyd (Stanford), Prof. Constantine Caramanis (UT-Austin)

`cvx_01`
* A note on notation
* Convex set definition
* Common convex sets
* Operations that preserve convexity
* Proper cone and generalized inequalities
* Minimum element
* Minimal element
* Inner product for matrices
* Dual norm
* Dual norm of some p-norm
* HÃ¶lder's inequality as generalization of Cauchy-Schwarz
* Dual cone
* Examples of dual cone
* Separating hyperplane theorem

`cvx_02`
* Convex function definition
* Common convex functions
* Convexity by restricting function to a line
* 1st and 2nd order condition for differentiable functions
* Conditions for nondifferentiable functions
* Convexity and monotone of (sub)gradient
* Epigraph
* Jensen's inequality
* Operations that preserve convexity
* Quasiconvexity
* Log-convexity
* Conjugate function

`cvx_03`
* Optimization in standard form and explicit constraints
* Feasibility of variable
* Feasibility of optimization problem
* Locally optimal points
* Domain of optimization problem and implicit constraints
* Convex optimization in standard form
* Any local optimal is global optimal for convex problem
* Optimality criterion for differentiable objective function
* Common equivalent convex formulations
* Linear program (LP)
* Quadratic program (QP)
* Second-order cone program (SOCP)
* Semidefinite program (SDP)

`cvx_04`
* Lagrangian
* Lagrange dual function
* Domain of dual function
* Lower bound property
* Lagrange dual function and conjugate function
* Lagrange dual problem
* Dual feasibility
* Implicit and explicit constraints in dual
* Weak and strong duality
* Slater's constraint qualification
* Inequality form of LP/QP and its dual
* Complementary slackness
* Karush-Kuhn-Tucker (KKT) conditions
* KKT as sufficient conditions for convex problem
* Perturbed primal and dual
* Global sensitivity
* Local sensitivity and interpretation of Lagrange multipliers

`cvx_05`
* Smooth function and bounded gradient
* Quadratic upper bound for smooth function
* Strongly convex function and quadratic lower bound
* Illustration of quadratic upper bound (smooth), quadratic lower bound (strongly convex), and linear lower bound (convex)

`cvx_06`
* A bound on suboptimality for smooth function
* Stronger monotone condition with co-coercivity
* A bound on suboptimality for strongly convex function
* Stronger monotone condition with coercivity

`cvx_07`
* Unconstrained optimization for differentiable convex function
* General descent method
* Requirement for search direction
* Line search for step size
* Gradient descent and 1st order approximation
* Gradient descent with ill-conditioned problem
* Convergence analysis of gradient descent for smooth and strongly convex functions
* Steepest descent method
* Search direction under arbitrary norm
* Quadratic norm search direction
* Geometric interpretation of quadratic norm search direction
* Newton's step from 2nd order approximation
* Newton's step as steepest descent direction under quadratic norm induced by local Hessian
