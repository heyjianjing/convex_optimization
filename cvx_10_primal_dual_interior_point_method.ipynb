{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Barrier interior point method"
      ],
      "metadata": {
        "id": "D4P76UVhbYme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For twice-differentiable convex functions $f_i$, we want to solve\n",
        "\n",
        "$$\\min f_0(x), \\text{s.t. } f_i(x)\\leq 0, i=1, \\cdots, m, \\,Ax=b$$\n",
        "\n",
        "where $A\\in \\mathbf{R}^{p \\times n}, \\, \\text{rank }A=p$, and $p^*$ is optimal value"
      ],
      "metadata": {
        "id": "19fx_-oNCIUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see previously that this problem can be formulated as a `sequence` of centering problem parameterized by variable $t$\n",
        "\n",
        "For each $t$, we solve an equality-constrained optimization\n",
        "\n",
        "$$\\min tf_0(x)+\\phi(x), \\text{s.t. } Ax=b$$\n",
        "\n",
        "where $\\phi(x)$ is the log-barrier function eliminating the inequality constraints\n",
        "\n",
        "$$\\phi(x)=-\\sum_{i=1}^m \\log (-f_i(x)), \\text{dom }\\phi=\\{x|f_1(x)<0,\\cdots,f_m(x)<0\\} $$\n",
        "\n",
        "Once we solve the centering problem and obtained $x^*(t)$, we get a set of dual feasible point $\\lambda^*, \\nu^*$ and the duality gap is given by\n",
        "\n",
        "$$p^*\\geq g(\\lambda^*(t), \\nu^*(t))=f_0(x^*(t))-\\frac{m}{t}$$"
      ],
      "metadata": {
        "id": "QH18fPsQr9Nh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then crank up $t$ and iteratively solve the `centering problem` to reduce the duality gap until desired accuracy\n",
        "\n",
        "This is known as the `barrier method`, and we get `Newton's step` by solving the KKT equations\n",
        "\n",
        "$$\\boxed{\\begin{bmatrix}\n",
        "t\\nabla^2 f_0(x)+\\nabla^2 \\phi(x) & A^T \\\\ A & 0\n",
        "\\end{bmatrix}\\begin{bmatrix}\n",
        "\\Delta x_{nt}\\\\ \\nu_{nt}\n",
        "\\end{bmatrix}=\\begin{bmatrix}\n",
        "-t\\nabla f_0(x)+\\nabla \\phi(x)\\\\0\n",
        "\\end{bmatrix}}$$"
      ],
      "metadata": {
        "id": "8ohhsQHnJR_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On central path, $x^*, \\lambda^*, \\nu^*$ almost satisfy the KKT conditions for the original problem, except for the complementary slackness $-\\lambda_i^*f_i(x^*)=1/t$"
      ],
      "metadata": {
        "id": "3r8tbcbTF4ZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Interpretation as reducing primal and dual residual"
      ],
      "metadata": {
        "id": "Gh6U9zHvuG58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also see barrier method as minimizing the residuals directly from the `original problem`, using Newton's method\n",
        "\n",
        "We write the `residual` as\n",
        "\n",
        "$$r(x, \\lambda, w)=\\begin{bmatrix}\\nabla f_0(x)+\\sum_{i=1}^m \\lambda_i \\nabla f_i(x)+ A^Tw \\\\ -\\text{diag}(\\lambda)f(x)-\\frac{1}{t}\\mathbf{1}\\\\Ax-b\\end{bmatrix}\\begin{array}{l}\\text{dual residual} \\\\ \\text{centrality residual}\\\\ \\text{primal residual}\\end{array}$$\n",
        "\n",
        "For the dual residual, we can also write as\n",
        "\n",
        "$$\\begin{align*}\n",
        "r_{d}&=\\nabla f_0(x)+\\sum_{i=1}^m \\lambda_i\\nabla f_i(x)+ A^Tw \\\\\n",
        "&=\\nabla f_0(x)+Df(x)^T \\lambda+ A^Tw\n",
        "\\end{align*}$$\n",
        "\n",
        "where\n",
        "\n",
        "$$Df(x) = \\begin{bmatrix}\\nabla f_1(x)^T \\\\ \\vdots \\\\ \\nabla f_m(x)^T\\end{bmatrix}$$\n",
        "\n",
        "We plug in $\\lambda_i=-1/(tf_i(x))$ to eliminate $\\lambda_i$\n",
        "\n",
        "$$r(x, w)=\\begin{bmatrix}\\nabla f_0(x)+\\sum_{i=1}^m \\frac{1}{-tf_i(x)}\\nabla f_i(x)+ A^Tw \\\\Ax-b\\end{bmatrix}\\begin{array}{l}\\text{dual residual} \\\\  \\text{primal residual}\\end{array}$$"
      ],
      "metadata": {
        "id": "whgKfpp0uKoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the primal-dual interpretation of Newton step, we `linearize` the residual and set it to zero\n",
        "\n",
        "\n",
        "$$r(x, w)+Dr(x, w)\\begin{bmatrix} \\Delta x_{nt} \\\\ \\Delta w_{nt} \\end{bmatrix}=0$$\n",
        "\n",
        "For the Jacobian, we have\n",
        "\n",
        "$$Dr(x, w)=\\begin{bmatrix}\\frac{\\partial r_1}{\\partial x} & \\frac{\\partial r_1}{\\partial w}\\\\ \\frac{\\partial r_2}{\\partial x} & \\frac{\\partial r_2}{\\partial w} \\end{bmatrix}=\\begin{bmatrix}\\nabla^2 f(x) & A^T\\\\ A & 0 \\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "OAALWCUcxTjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More specifically\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\nabla^2f(x)&=\\nabla \\left(\\nabla f_0(x)+\\sum_{i=1}^m\\frac{1}{-tf_i(x)}\\nabla f_i(x)\\right)\\\\\n",
        "&\\nabla \\left(\\sum_{i=1}^m\\frac{1}{-f_i(x)}\\nabla f_i(x)\\right)=\\sum_{i=1}^m\\frac{1}{f_i(x)^2}\\nabla f_i(x)\\nabla f_i(x)^T +\\sum_{i=1}^m\\frac{1}{-f_i(x)}\\nabla^2 f_i(x) \\\\\n",
        "&=\\nabla^2 f_0(x) + \\sum_{i=1}^m\\frac{1}{tf_i(x)^2}\\nabla f_i(x)\\nabla f_i(x)^T +\\sum_{i=1}^m\\frac{1}{-tf_i(x)}\\nabla^2 f_i(x)\n",
        "\\end{align*}$$"
      ],
      "metadata": {
        "id": "e7my8H_IIe1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $w = w + \\Delta w_{nt}$, we have\n",
        "\n",
        "$$H\\Delta x_{nt} + A^Tw = -g, \\,\\,A\\Delta x_{nt}=0$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\\begin{align*}\n",
        "H&=\\nabla^2 f_0(x) + \\sum_{i=1}^m\\frac{1}{tf_i(x)^2}\\nabla f_i(x)\\nabla f_i(x)^T +\\sum_{i=1}^m\\frac{1}{-tf_i(x)}\\nabla^2 f_i(x)\\\\\n",
        "g &= \\nabla f_0(x) + \\sum_{i=1}^m \\frac{1}{-tf_i(x)}\\nabla f_i(x)\n",
        "\\end{align*}$$"
      ],
      "metadata": {
        "id": "nybFi3QjONRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare to the expression of $\\nabla \\phi(x)$ and $\\nabla^2 \\phi(x)$, we see that\n",
        "\n",
        "$$H=\\nabla^2 f_0(x) + \\frac{1}{t}\\nabla^2 \\phi(x),\\,\\, g=\\nabla f_0(x)+\\frac{1}{t}\\nabla \\phi(x)$$\n",
        "\n",
        "Compare to the centering problem\n",
        "\n",
        "$$\\begin{bmatrix}\n",
        "t\\nabla^2 f_0(x)+\\nabla^2 \\phi(x) & A^T \\\\ A & 0\n",
        "\\end{bmatrix}\\begin{bmatrix}\n",
        "\\Delta x_{nt}\\\\ \\nu_{nt}\n",
        "\\end{bmatrix}=\\begin{bmatrix}\n",
        "-t\\nabla f_0(x)+\\nabla \\phi(x)\\\\0\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "we see that Newton step for `primal` variable from the solving the residual of the `original` problem (based on the modified KKT conditions) is the same as directly solving the KKT equations of the `centering` problem\n",
        "\n",
        "For the `dual` variable, we get a scaled version compared to solving the KKT equations\n",
        "\n",
        "$$w=\\frac{1}{t}\\nu_{nt}$$"
      ],
      "metadata": {
        "id": "Vn8Z3Gt1Pi83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Primal-dual interior point method"
      ],
      "metadata": {
        "id": "HAN5Ejiqo9l2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An alternative to the barrier method is the primal-dual method, which does not get rid of $\\lambda_i$ and instead solves the complete equations of residuals for $\\Delta x, \\Delta \\lambda, \\Delta \\nu$ (analogous to infeasible start Newton's method)\n",
        "\n",
        "The linearized residual becomes\n",
        "\n",
        "$$r(x, \\lambda, \\nu)+Dr(x, \\lambda, \\nu)\\begin{bmatrix} \\Delta x \\\\ \\Delta \\lambda \\\\ \\Delta \\nu \\end{bmatrix}=0$$\n",
        "\n",
        "where\n",
        "\n",
        "$$r(x, \\lambda, \\nu)=\\begin{bmatrix}\\nabla f_0(x)+\\sum_{i=1}^m \\lambda_i \\nabla f_i(x)+ A^T\\nu \\\\ -\\text{diag}(\\lambda)f(x)-\\frac{1}{t}\\mathbf{1}\\\\Ax-b\\end{bmatrix}\\begin{array}{l}\\text{dual residual} \\\\ \\text{centrality residual}\\\\ \\text{primal residual}\\end{array}$$\n",
        "\n",
        "For the Jacobian, we have\n",
        "\n",
        "$$Dr(x, \\lambda, \\nu)=\\begin{bmatrix}\\nabla^2 f_0(x)+\\sum_{i=1}^m \\lambda_i \\nabla^2 f_i(x) & Df(x)^T & A^T \\\\\n",
        "-\\text{diag}(\\lambda) Df(x) & -\\text{diag}(f(x)) & 0 \\\\\n",
        "A & 0 & 0 \\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "fy8fV1uwpAPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Surrogate duality gap"
      ],
      "metadata": {
        "id": "4HhIyetnrvBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the primal-dual method does not guarantee feasibility at each iteration, except in the limit as the algorithm converges, surrogate duality gap is often used\n",
        "\n",
        "For any $x$ such that $f(x)\\leq 0$ and $\\lambda \\geq 0$, the surrogate duality gap is given by\n",
        "\n",
        "$$\\hat{\\eta}(x, \\lambda) = -f(x)^T\\lambda$$\n",
        "\n",
        "Obviously, the surrogate duality gap becomes duality gap $m/t$, if $x, \\lambda, \\nu$ are feasible"
      ],
      "metadata": {
        "id": "kRixsZ02rwo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Steps for primal-dual method"
      ],
      "metadata": {
        "id": "qDmCo30gsnYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given $x$ such that $f_i(x)<0, i=1, \\cdots, m$, $\\lambda >0, \\mu>1$, repeat\n",
        "\n",
        "* Compute surrogate duality gap $\\hat{\\eta}$\n",
        "* $t=\\mu m /\\hat{\\eta}$\n",
        "* Solve primal-dual search direction $\\Delta y=\\begin{bmatrix} \\Delta x \\\\ \\Delta \\lambda \\\\ \\Delta \\nu \\end{bmatrix}$\n",
        "* Line search to determine step size $s$\n",
        "* $y \\leftarrow y + s\\Delta y$\n",
        "\n",
        "until $\\|r_p\\|_2\\leq \\epsilon_{\\text{feas}}, \\|r_d\\|_2\\leq \\epsilon_{\\text{feas}}$, and $\\hat{\\eta}\\leq \\epsilon$\n",
        "\n",
        "That is, we check both residual (how far variables are from being feasible) and surrogate duality gap"
      ],
      "metadata": {
        "id": "Dz3p9oPYsqgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Step size"
      ],
      "metadata": {
        "id": "x4TZ8ZdeuxTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine step size, the line search ensures that $\\lambda >0$ and $f(x)<0$\n",
        "\n",
        "We first compute the largest positive step length not exceeding one that gives $\\lambda^+\\geq 0$\n",
        "\n",
        "$$s^{\\max}=\\min\\{1, \\min\\{-\\lambda_i/\\Delta \\lambda_i|\\Delta \\lambda_i<0\\}\\}$$\n",
        "\n",
        "Then, we start with $s=0.99s^{\\max}$ and do $s\\leftarrow s\\beta$ until\n",
        "\n",
        "* $f(x^+)<0$ and\n",
        "* $\\|r(x^+, \\lambda^+, \\nu^+)\\|_2\\leq (1 - \\alpha s)\\|r(x, \\lambda, \\nu)\\|_2$\n"
      ],
      "metadata": {
        "id": "OwEEQT_tu3Sp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LOWKEQy3Or4F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}